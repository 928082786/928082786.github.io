# Personal Page
<table border="0">
  <tr>
    <td width="60%">
      <h1>Xuan Chen</h1>
      <p><b>Tel: 13371485795</b></p>
      <p><b>Email: 928082786@qq.com</b></p>
      <p><b>Github:<a href="https://github.com/928082786">
      https://github.com/928082786</a></b> </p>
      <p><b>Address:  Baqiao, Xi'an City, Shaanxi Province</b></p>
      <p><b>Description:  <font face="æ¥·ä½“" size=3pt>I am a graduate student of AFEU. My primary interests are deep learning, adversarial attacks, and backdoor attacks. Besides, the researches of quantum computing and quantum machine learning also attract me much.</font></b></p> 
    </td>
    <td width="40%">
      <img src="me.jpg" width="100%">    
    </td>
  </tr>
</table>



## The recent research

1. Boundary augment: A data augment method to defend poison attack
ðŸ“–[Paper](https://ietresearch.onlinelibrary.wiley.com/doi/full/10.1049/ipr2.12325)

2. Use Procedural Noise to Achieve Backdoor Attack
ðŸ“–[Paper](https://www.researchgate.net/publication/354345187_Use_Procedural_Noise_to_Achieve_Backdoor_Attack)


## Shared Pizza
### Adversarial attack
- ðŸš€[All Adversarial Example Papers](https://nicholas.carlini.com/writing/2019/all-adversarial-example-papers.html)
  > ***This website collects nearly all papers about the adversarial attack. It was built by Nicholas Carlini, a famous researcher in the deep learning security field.***

- ðŸš€[Trusted-AI/adversarial-robustness-toolbox](https://github.com/Trusted-AI/adversarial-robustness-toolbox)
  > ***Adversarial Robustness Toolbox (ART) is a Python library for Machine Learning Security. ART provides tools that enable developers and researchers to defend and evaluate Machine Learning models and applications against the adversarial threats of Evasion, Poisoning, Extraction, and Inference. â€”â€”IBM Trust AI***

- ðŸš€[cleverhans](https://github.com/cleverhans-lab/cleverhans)
  > ***The official library, built by GoodFellow and Nicholas Carlini, contains many attack and defense methods of adversarial attack. In the future version v4.0.0, The attacks in PyTorch will be priority processing, however, Tenserflow is mainstream in the current version.***

- ðŸš€[cleverhans blog](http://www.cleverhans.io/)
  > ***The cleverhans blog is an open blog to review the reports about security and privacy in machine learning. However, the update speed is not quick.***

### Backdoor attack
- ðŸš€[usnistgov/trojai-literature](https://github.com/usnistgov/trojai-literature)
  > ***This is a github repo, containing curated papers and arXiv articles that are related to Trojan attacks, backdoor attacks, and data poisoning on neural networks and machine learning systems.***

- ðŸš€[ain-soph/trojanzoo](https://github.com/ain-soph/trojanzoo)
  > ***This is a github repo, providing a baseline evaluation framework for the attack and defense methods. The [paper](https://arxiv.org/abs/2012.09302) illustrated the detailed contents of Trojanzoo***

- ðŸš€[Trusted-AI/adversarial-robustness-toolbox](https://github.com/Trusted-AI/adversarial-robustness-toolbox)
